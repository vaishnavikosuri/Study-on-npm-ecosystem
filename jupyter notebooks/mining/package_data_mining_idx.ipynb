{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAbVoPDmJKrR"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "055IeVdhRPRa",
        "outputId": "8d73c70f-08ff-4ad4-9196-bd6d1aeaa8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydriller\n",
            "  Downloading PyDriller-2.6-py3-none-any.whl (33 kB)\n",
            "Collecting gitpython (from pydriller)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from pydriller) (2023.4)\n",
            "Requirement already satisfied: types-pytz in /usr/local/lib/python3.10/dist-packages (from pydriller) (2024.1.0.20240203)\n",
            "Collecting lizard (from pydriller)\n",
            "  Downloading lizard-1.17.10-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython->pydriller)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->pydriller)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: lizard, smmap, gitdb, gitpython, pydriller\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 lizard-1.17.10 pydriller-2.6 smmap-5.0.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "import sqlite3\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "from google.colab import drive\n",
        "import random\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "!pip install pydriller\n",
        "from pydriller import Repository\n",
        "from urllib.parse import urlparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXIhQ2Nauqdv",
        "outputId": "95251113-d68c-40dc-e828-c00cd25e06ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "# change location as per your convenience\n",
        "# final_packages.txt (containing json dump of list of npm package names to be mined) should be present at this location\n",
        "# database will be saved at this location\n",
        "os.chdir(\"/content/gdrive/Shareddrives/ECS 260/final\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TkJKg7MJOpQ"
      },
      "source": [
        "# Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSziMK10yLPd"
      },
      "outputs": [],
      "source": [
        "def add_column_if_not_exists(cursor, table_name, column_name, column_definition):\n",
        "    # check if the column already exists\n",
        "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
        "    existing_columns = [column[1] for column in cursor.fetchall()]\n",
        "\n",
        "    if column_name not in existing_columns:\n",
        "        # add the column if it does not exist\n",
        "        cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column_name} {column_definition};\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qY13_R3fJlS"
      },
      "outputs": [],
      "source": [
        "def GET(json_obj, keys, default = None):\n",
        "  if not isinstance(keys, list):\n",
        "    keys = [keys]\n",
        "  current = json_obj\n",
        "  try:\n",
        "    for key in keys:\n",
        "      if isinstance(current, list):\n",
        "        key = int(key)\n",
        "      current = current[key]\n",
        "    return current\n",
        "  except (TypeError, IndexError, KeyError):\n",
        "    return default\n",
        "\n",
        "def isValid(value):\n",
        "  if isinstance(value, list):\n",
        "    return not len(value) == 0\n",
        "  return value != None and value != \"\"\n",
        "\n",
        "def getN(arr):\n",
        "  return len(arr) if isValid(arr) else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Th-HbpfRFN"
      },
      "outputs": [],
      "source": [
        "# fetch json from an API endpoint\n",
        "def fetch_response_without_fail(url, params = {}, headers = {}, shouldScrap = False):\n",
        "  retry_count = 0\n",
        "  max_retries = 15\n",
        "  time_interval = 10\n",
        "  status = \"\"\n",
        "  while retry_count < max_retries:\n",
        "    try:\n",
        "      response = requests.get(url, params=params, headers=headers)\n",
        "\n",
        "      if response.status_code == 200:\n",
        "        status = str(response.status_code)\n",
        "        if shouldScrap:\n",
        "          return (status, response)\n",
        "        else:\n",
        "          return (status, response.json())\n",
        "      elif response.status_code == 404:\n",
        "        status = str(response.status_code)\n",
        "        print(f\"Error: {response.status_code}, skipping url {url}\")\n",
        "        return (status, None)\n",
        "      else:\n",
        "        status = str(response.status_code)\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        print(params)\n",
        "        retry_count += 1\n",
        "        print(f\"Retrying in {time_interval} seconds... (Retry {retry_count}/{max_retries})\")\n",
        "        if response.status_code == 429:\n",
        "          retry_after = response.headers.get('Retry-After')\n",
        "          if retry_after:\n",
        "            print(\"Retrying after\", retry_after + 5, \"Seconds\")\n",
        "            time.sleep(int(retry_after) + 5)\n",
        "          else:\n",
        "            time.sleep(time_interval)\n",
        "        else:\n",
        "          time.sleep(time_interval)\n",
        "\n",
        "    except Exception as e:\n",
        "      status = f\"Exception occurred: {e}\"\n",
        "      print(status)\n",
        "      retry_count += 1\n",
        "      print(f\"Retrying in {time_interval} seconds... (Retry {retry_count}/{max_retries})\")\n",
        "      time.sleep(time_interval)\n",
        "\n",
        "  print(f\"Max retries reached. Unable to fetch data from {url}.\")\n",
        "  return (status, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzyVBE3N1R5F"
      },
      "outputs": [],
      "source": [
        "def get_lagging_dependencies_count(dependencies):\n",
        "  status = \"erred\"\n",
        "  if not isValid(dependencies):\n",
        "    return (status, None)\n",
        "\n",
        "  lagging_dependencies = 0\n",
        "  for dependency, specified_version in dependencies.items():\n",
        "    if specified_version == 'latest':\n",
        "      continue\n",
        "\n",
        "    (status, dependency_data) = fetch_response_without_fail(f'https://registry.npmjs.org/{dependency}/latest')\n",
        "    if not status == '200':\n",
        "      # skipping count if dependency doesn't exist for some reason\n",
        "      continue\n",
        "    latest_version = GET(dependency_data, 'version')\n",
        "    if latest_version and specified_version != latest_version:\n",
        "      lagging_dependencies += 1\n",
        "\n",
        "  return (\"success\", lagging_dependencies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUBwUbipGYs3"
      },
      "outputs": [],
      "source": [
        "def extract_github_url(repo_url):\n",
        "  if not isValid(repo_url):\n",
        "    return None\n",
        "  repo_url_lowered = repo_url.lower()\n",
        "  if not repo_url_lowered.find('gist.github.com') == -1:\n",
        "    return None\n",
        "  if not repo_url_lowered.find('gitee.com') == -1:\n",
        "    return None\n",
        "  if not repo_url_lowered.find('bitbucket') == -1:\n",
        "    return None\n",
        "\n",
        "  github_idx = repo_url_lowered.find('github.com')\n",
        "  if github_idx == -1:\n",
        "    if repo_url.endswith('.git'):\n",
        "      repo_url = repo_url[:-4]\n",
        "      if ':' in repo_url:\n",
        "        repo_url = repo_url.split(':')[-1]\n",
        "      path_segments = repo_url.split('/')\n",
        "      if len(path_segments) >= 2 and all(len(path) > 0 for path in path_segments[-2:]):\n",
        "        author_repo = \"/\".join(path_segments[-2:])\n",
        "        return f\"https://github.com/{author_repo}\"\n",
        "      return None\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  repo_url = repo_url[github_idx + len('github.com'):]\n",
        "  path_segments = repo_url.split('/')\n",
        "  if len(path_segments) >= 2 and all(len(path) > 0 for path in path_segments[-2:]):\n",
        "    author_repo = \"/\".join(path_segments[-2:])\n",
        "    author_repo = author_repo[:-4] if author_repo.endswith(\".git\") else author_repo\n",
        "    return f\"https://github.com/{author_repo}\"\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQiDlyt1RhAh",
        "outputId": "7ad83c2f-df06-4832-f30e-62e606619ef5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://github.com/ibm/ibm-cos-sdk-js'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "extract_github_url('git+https://github.com/ibm/ibm-cos-sdk-js.git')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoT33POyPDIZ"
      },
      "outputs": [],
      "source": [
        "def extract_snyk_score(soup, category):\n",
        "    selector = f'.scores li span:contains(\"{category}\")'\n",
        "    category_element = soup.select_one(selector)\n",
        "\n",
        "    if category_element:\n",
        "        category_score = category_element.find_next('span', class_='vue--pill__body').get_text(strip=True)\n",
        "        return category_score.upper()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def scrap_snyk(package):\n",
        "  status = \"erred\"\n",
        "  try:\n",
        "    status, response = fetch_response_without_fail(f\"https://snyk.io/advisor/npm-package/{package}\", shouldScrap=True)\n",
        "    if not status == '200':\n",
        "      return (status, None)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    health_score_div = soup.select_one('.number span')\n",
        "    if not health_score_div:\n",
        "      if soup.find('div', class_='package-extra').find('p', class_='heading', string='This is a malicious package'):\n",
        "        # For malicious packages, health score is 0\n",
        "        health_score = 0\n",
        "      else:\n",
        "        # some error\n",
        "        status = f\"erred, element not found, status:{status}\"\n",
        "        health_score = None\n",
        "      return (status, {\n",
        "        \"health_score\": health_score,\n",
        "        \"security\": None,\n",
        "        \"popularity\": None,\n",
        "        \"maintenance\": None,\n",
        "        \"community\": None\n",
        "      })\n",
        "    health_score = health_score_div.get_text(strip=True).split('/')[0].strip()\n",
        "    try:\n",
        "      health_score = int(health_score)\n",
        "    except:\n",
        "      health_score\n",
        "\n",
        "    return (status, {\n",
        "      \"health_score\": health_score,\n",
        "      \"security\": extract_snyk_score(soup, 'security'),\n",
        "      \"popularity\": extract_snyk_score(soup, 'popularity'),\n",
        "      \"maintenance\": extract_snyk_score(soup, 'maintenance'),\n",
        "      \"community\": extract_snyk_score(soup, 'community')\n",
        "    })\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    status = str(response.status_code)\n",
        "    print(f\"Error scraping snyk for {package}: {e}\")\n",
        "\n",
        "  print(f\"Error scraping snyk for {package}\")\n",
        "  return (status, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLfJF5e7Uh8I"
      },
      "outputs": [],
      "source": [
        "def scrap_repo(repo_url):\n",
        "  status = \"erred\"\n",
        "  try:\n",
        "    status, response = fetch_response_without_fail(repo_url, shouldScrap=True)\n",
        "    if not status == '200':\n",
        "      return (status, None)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    border_grid_rows = soup.find_all(class_='BorderGrid-row')\n",
        "    contributors = None\n",
        "    for border_grid_row in border_grid_rows:\n",
        "      text = border_grid_row.text.strip()\n",
        "      if text.startswith('Contributors'):\n",
        "        span_element = border_grid_row.find('span')\n",
        "        if span_element:\n",
        "          span_text = span_element.get_text(strip=True).replace(\",\", \"\")\n",
        "          try:\n",
        "            contributors = int(span_text)\n",
        "          except:\n",
        "            contributors = span_text\n",
        "\n",
        "    commit_anchor_tag = soup.find(\"a\", class_=\"react-last-commit-history-group\")\n",
        "    no_of_commits = None\n",
        "    if commit_anchor_tag:\n",
        "      # Find all span elements within the anchor tag\n",
        "      spans = commit_anchor_tag.find_all(\"span\")\n",
        "      spans = spans[0].find_all(\"span\")\n",
        "\n",
        "      if len(spans) > 1:\n",
        "        commit_count_span = spans[1]\n",
        "        commit_count_text = commit_count_span.get_text(strip=True)\n",
        "        no_of_commits = int(''.join(filter(str.isdigit, commit_count_text)))\n",
        "\n",
        "    return (status, {\"contributors\": contributors, \"no_of_commits\": no_of_commits})\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    status = str(response.status_code)\n",
        "    print(f\"Error scraping github repo {repo_url}: {e}\")\n",
        "\n",
        "  print(f\"Error scraping github repo {repo_url}\")\n",
        "  return (status, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q-jm886gGwy"
      },
      "outputs": [],
      "source": [
        "def scrap_repo_net(repo_url):\n",
        "  status = \"erred\"\n",
        "  try:\n",
        "    status, response = fetch_response_without_fail(repo_url + '/network/dependents', shouldScrap=True)\n",
        "    if not status == '200':\n",
        "      return (status, None)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btn_links = soup.find_all('a', class_='btn-link')\n",
        "    dependants_count = None\n",
        "    dependant_repos_count = None\n",
        "    for btn_link in btn_links:\n",
        "      text_content = btn_link.get_text(strip=True)\n",
        "\n",
        "      if \"Repositories\" in text_content:\n",
        "          dependants_count = int(''.join(filter(str.isdigit, (text_content.split()[0]))))\n",
        "      elif \"Packages\" in text_content:\n",
        "          dependant_repos_count = int(''.join(filter(str.isdigit, (text_content.split()[0]))))\n",
        "\n",
        "    return (status, {\"dependants_count\": dependants_count, \"dependant_repos_count\": dependant_repos_count})\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    status = str(response.status_code)\n",
        "    print(f\"Error scraping github repo {repo_url}: {e}\")\n",
        "\n",
        "  print(f\"Error scraping github repo {repo_url}\")\n",
        "  return (status, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSHVBUsigowJ"
      },
      "outputs": [],
      "source": [
        "def count_lines_of_code(repo_url):\n",
        "  total_lines_of_code = 0\n",
        "  filtered_lines_of_code = 0\n",
        "  file_set = set()\n",
        "  try:\n",
        "    # Iterate over commits in the repository\n",
        "    for commit in Repository(repo_url).traverse_commits():\n",
        "      # Iterate over modified files in each commit\n",
        "      for modified_file in commit.modified_files:\n",
        "        # Check if the file is a source code file\n",
        "        if modified_file.filename.endswith(('.py', '.json', '.md', '.html', '.yaml', '.yml', '.xml','.sh', '.css','.scss','.ts','.jsx','.tsx')):\n",
        "          filtered_lines_of_code = filtered_lines_of_code+ (modified_file.added_lines - modified_file.deleted_lines)\n",
        "\n",
        "        lines_of_code = modified_file.added_lines - modified_file.deleted_lines\n",
        "        file_set.add(modified_file.filename)\n",
        "        total_lines_of_code += lines_of_code\n",
        "  except Exception as e:\n",
        "    print(\"Didn't Work\", repo_url)\n",
        "\n",
        "  return total_lines_of_code, filtered_lines_of_code, len(file_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-NQdxfMtX3N"
      },
      "outputs": [],
      "source": [
        "def fetch_package_data_from_db(db_path, package_name, table_name):\n",
        "  curr_conn = sqlite3.connect(db_path)\n",
        "  curr_cursor = curr_conn.cursor()\n",
        "\n",
        "  curr_cursor.execute(f\"SELECT * FROM {table_name} WHERE package=?\", (package_name,))\n",
        "  curr_row = curr_cursor.fetchone()\n",
        "\n",
        "  curr_conn.close()\n",
        "\n",
        "  if curr_row:\n",
        "    column_names = [description[0] for description in curr_cursor.description]\n",
        "    package_data = dict(zip(column_names, curr_row))\n",
        "    return package_data\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi63NiGtxDqI"
      },
      "source": [
        "# Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3XJDIoaKrsi",
        "outputId": "e0e31e5d-92fa-44f7-dd80-04ba5ecff6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows to be mined:  3333\n"
          ]
        }
      ],
      "source": [
        "gh_token = '<your_github_access_token>'\n",
        "li_api_key = '<your_librarie.io_api_token>'\n",
        "# put index according to the no. of partitions\n",
        "idx = 1\n",
        "\n",
        "# final_packages.txt should have json dump of list of npm package names to be mined\n",
        "with open('final_packages.txt', \"r\") as file:\n",
        "  final_packages = file.read()\n",
        "final_packages = json.loads(final_packages)\n",
        "\n",
        "# specify how many parts you want to distribute the mining into\n",
        "total_parts = 9\n",
        "i = idx - 1\n",
        "part_size = len(final_packages) // total_parts\n",
        "package_list = final_packages[i * part_size:(i + 1) * part_size if i < total_parts - 1 else len(final_packages)]\n",
        "print(\"Total rows to be mined: \", len(package_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kyxTPar_4kd"
      },
      "source": [
        "# DB Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZrKGN8K_Ew_"
      },
      "outputs": [],
      "source": [
        "# init database and cursor\n",
        "conn = sqlite3.connect(f\"database_{idx}.db\")\n",
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWS2Pb_JQ5rU"
      },
      "outputs": [],
      "source": [
        "cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS package_data (\n",
        "        package TEXT\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtdzF8hYywx8"
      },
      "outputs": [],
      "source": [
        "# columns other than `package`\n",
        "columns = [\n",
        "    ['npm_api_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from npm API\n",
        "    #      possible values: 200 if everything is mined\n",
        "    #                       404 if package is missing/not found\n",
        "    #                       etc...\n",
        "    # IMP: further mining is continued only if this status is 200\n",
        "\n",
        "    ['latest_version', 'TEXT DEFAULT NULL'],\n",
        "    # Def: latest version name of the package\n",
        "    # Source: npm API\n",
        "\n",
        "    ['no_of_versions', 'INT DEFAULT NULL'],\n",
        "    # Def: total no of versions released for this package\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['keywords', 'TEXT DEFAULT NULL'],\n",
        "    # Def: json dump of list of keywords\n",
        "    # Source: npm API\n",
        "\n",
        "    ['no_of_users', 'INT DEFAULT NULL'],\n",
        "    # Def: no of npm users who have starred this package w.r.t. npm (not github)\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['has_readme', 'INT DEFAULT NULL'],\n",
        "    # Def: if the package has a readme file provided with it\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['has_homepage', 'INT DEFAULT NULL'],\n",
        "    # Def: if the package has a homepage\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['last_modified_timestamp', 'TEXT DEFAULT NULL'],\n",
        "    # Def: timestamp when the package was last modified in npm registry\n",
        "    # Source: npm API\n",
        "\n",
        "    ['created_timestamp', 'TEXT DEFAULT NULL'],\n",
        "    # Def: timestamp when the package was first published in npm registry\n",
        "    # Source: npm API\n",
        "\n",
        "    ['unpublished_timestamp', 'TEXT DEFAULT NULL'],\n",
        "    # Def: timestamp when the package was unpublished from npm registry\n",
        "    # Source: npm API\n",
        "    # IMP: further mining is discontinued if this has been found valid\n",
        "    #      as we do not get any repository url from this response\n",
        "\n",
        "    ['version_history_timestamps', 'TEXT DEFAULT NULL'],\n",
        "    # Def: json dump of dictionary of version-release_timestamp pairs\n",
        "    # Source: npm API\n",
        "\n",
        "    ['is_deprecated', 'INT DEFAULT NULL'],\n",
        "    # Def: flag to denote if package is deprecated\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['no_of_dependencies', 'INT DEFAULT 0'],\n",
        "    # Def: total no. of dependencies and devDependencies\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['lagging_dependencies_count', 'INT DEFAULT NULL'],\n",
        "    # Def: count of lagging dependencies\n",
        "    #      lagging dependency: dependency that is not the latest version of itself\n",
        "    #                          for each dependency listed in the package's metadata,\n",
        "    #                          compare the version specified in the package with\n",
        "    #                          the latest available version.\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['lagging_dependencies_count_status', 'INT DEFAULT NULL'],\n",
        "    # Def: response status on calling lagging dependencies count function\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['unpack_size', 'INT DEFAULT NULL'],\n",
        "    # Def: the total byte of the unpacked files in the tarball\n",
        "    # Source: npm API\n",
        "\n",
        "    ['file_count', 'INT DEFAULT NULL'],\n",
        "    # Def: the number of files in the tarball, folder excluded\n",
        "    # Source: npm API\n",
        "\n",
        "    ['has_repository', 'INT DEFAULT NULL'],\n",
        "    # Def: if the package has a repository present (can be any type including github, bitbucket, etc.)\n",
        "    # Source: npm API, derived\n",
        "\n",
        "    ['repository_type', 'TEXT DEFAULT NULL'],\n",
        "    # Def: type of repository as mentioned in metadata\n",
        "    # Source: npm API\n",
        "\n",
        "    ['repository_url', 'TEXT DEFAULT NULL'],\n",
        "    # Def: url of repository as mentioned in metadata\n",
        "    # Source: npm API\n",
        "\n",
        "    ['git_repository_url', 'TEXT DEFAULT NULL'],\n",
        "    # Def: github repository url, formatted properly\n",
        "    # Source: npm API, derived using extract_github_url(repository_url)\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['li_api_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling libraries.io API\n",
        "    #      possible values: 200 if API working fine\n",
        "    #                       404 if API resource not found\n",
        "    #                       etc...\n",
        "    # Source: libraries.io API\n",
        "\n",
        "    ['rank', 'TEXT DEFAULT NULL'],\n",
        "    # Def: popularity rank\n",
        "    # Source: libraries.io API\n",
        "\n",
        "    ['dependants_count', 'TEXT DEFAULT NULL'],\n",
        "    # Def: no. of packages that are dependent on current package\n",
        "    #      this is overwritten if its obtained from github page scrapping later on\n",
        "    # Source: libraries.io API\n",
        "\n",
        "    ['dependant_repos_count', 'TEXT DEFAULT NULL'],\n",
        "    # Def: no. of repositories that are dependent on current package\n",
        "    #      this is overwritten if its obtained from github page scrapping later on\n",
        "    # Source: libraries.io API\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['git_repository_url_final', 'TEXT DEFAULT NULL'],\n",
        "    # Def: final github repository url after accounting for any redirects in git_repository_url\n",
        "    # Source: git_repository_url, derived\n",
        "\n",
        "    ['git_repository_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling git_repository_url_final\n",
        "    #      possible values: 200 if repo working fine\n",
        "    #                       404 if repo not found, possibly made private or removed\n",
        "    #                       etc...\n",
        "    # IMP: further github mining is continued only if this status is 200\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['gh_api_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling github API\n",
        "    #      possible values: 200 if API working fine\n",
        "    #                       404 if API resource not found\n",
        "    #                       etc...\n",
        "    # IMP: forks, stars, watchers, avg_commit_freq is mined correctly if this status is 200\n",
        "    # Source: github API\n",
        "\n",
        "    ['forks', 'INT DEFAULT NULL'],\n",
        "    # Def: no. of forks\n",
        "    # Source: github API\n",
        "\n",
        "    ['stars', 'INT DEFAULT NULL'],\n",
        "    # Def: no. of stars\n",
        "    # Source: github API\n",
        "\n",
        "    ['watchers', 'INT DEFAULT NULL'],\n",
        "    # Def: no. of watchers\n",
        "    # Source: github API\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['gh_issue_api_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling github issues API\n",
        "    #      possible values: 200 if API working fine\n",
        "    #                       404 if API resource not found\n",
        "    #                       etc...\n",
        "    # IMP: issues is mined correctly if this status is 200\n",
        "    # Source: github API\n",
        "\n",
        "    ['issues', 'INT DEFAULT NULL'],\n",
        "    # Def: latest version name of the package\n",
        "    # Source: github issues API\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['gh_pr_api_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling github pr API\n",
        "    #      possible values: 200 if API working fine\n",
        "    #                       404 if API resource not found\n",
        "    #                       etc...\n",
        "    # IMP: pr is mined correctly if this status is 200\n",
        "    # Source: github pr API\n",
        "\n",
        "    ['pr', 'INT DEFAULT NULL'],\n",
        "    # Def: latest version name of the package\n",
        "    # Source: github API\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['gh_scrapping_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling github repository page of current package\n",
        "    #      possible values: 200 if webpage working fine\n",
        "    #                       404 if webpage not found\n",
        "    #                       etc...\n",
        "    # Source: github repository page scrapping\n",
        "\n",
        "    ['contributors', 'INT DEFAULT NULL'],\n",
        "    # Def: no. of contributors in current package's repository\n",
        "    # Source: github repository page scrapping\n",
        "\n",
        "    ['no_of_commits', 'INT DEFAULT NULL'],\n",
        "    # Def: total no. of commits in current package's repository\n",
        "    # Source: github repository page scrapping\n",
        "\n",
        "    ['avg_commit_freq', 'REAL DEFAULT NULL'],\n",
        "    # Def: frequency of commit w.r.t lifespan of repository, in no. per days\n",
        "    # Source: github repository page scrapping and created_at from github API, derived\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['gh_net_scrapping_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling github repository's network page scrapping\n",
        "    #      possible values: 200 if webpage working fine\n",
        "    #                       404 if webpage not found\n",
        "    #                       etc...\n",
        "    # Source: github repository's network page scrapping\n",
        "\n",
        "    ['dependants_count', 'INT DEFAULT NULL'],\n",
        "    # Def: no. of packages that are dependent on current package\n",
        "    # Source: github repository's network page scrapping\n",
        "\n",
        "    ['dependant_repos_count', 'INT DEFAULT NULL'],\n",
        "    # Def: no. of repositories that are dependent on current package\n",
        "    # Source: github repository's network page scrapping\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['total_lines_of_code', 'INT DEFAULT NULL'],\n",
        "    # Def: LOC count\n",
        "    # Source: pydriller\n",
        "\n",
        "    ['filtered_lines_of_code', 'INT DEFAULT NULL'],\n",
        "    # Def: filtered LOC count\n",
        "    # Source: pydriller\n",
        "\n",
        "    ['no_of_files', 'INT DEFAULT NULL'],\n",
        "    # Def: no. of files\n",
        "    # Source: pydriller\n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "    ['snyk_scrapping_status', 'TEXT DEFAULT NULL'],\n",
        "    # Def: response status from calling snyk package advisor webpage\n",
        "    #      possible values: 200 if webpage working fine\n",
        "    #                       404 if webpage not found\n",
        "    #                       etc...\n",
        "    # Source: snyk package advisor webpage scrapping\n",
        "\n",
        "    ['health_score', 'INT DEFAULT NULL'],\n",
        "    # Def: comprehensive evaluation of an npm package's overall health, considering multiple factors such as quality,\n",
        "    #      security, and maintenance. It aids developers in assessing the package's overall quality and reliability\n",
        "    # Source: snyk package advisor webpage scrapping\n",
        "\n",
        "    ['security', 'TEXT DEFAULT NULL'],\n",
        "    # Def: evaluation of package vulnerability, considering the presence and severity of known security issues\n",
        "    # Source: snyk package advisor webpage scrapping\n",
        "\n",
        "    ['popularity', 'TEXT DEFAULT NULL'],\n",
        "    # Def: metric that represents the widespread use of a package in the development community, indicating stability and maintenance\n",
        "    # Source: snyk package advisor webpage scrapping\n",
        "\n",
        "    ['maintenance', 'TEXT DEFAULT NULL'],\n",
        "    # Def: metric to measure the responsiveness of package maintainers to issues, updates, and community interactions, enhancing stability\n",
        "    # Source: snyk package advisor webpage scrapping\n",
        "\n",
        "    ['community', 'TEXT DEFAULT NULL'],\n",
        "    # Def: metric to represent the level of community support and engagement, contributing to the overall health of the package\n",
        "    # Source: snyk package advisor webpage scrapping\n",
        "]\n",
        "\n",
        "# adding columns to the table\n",
        "for col in columns:\n",
        "  add_column_if_not_exists(cursor, 'package_data', col[0], col[1])\n",
        "\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHt0R-BPI1NN",
        "outputId": "207079aa-6c5f-4bfa-c195-d6280de2ad07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    package npm_api_status latest_version  \\\n",
              "0                 le-shared-utils-teste-app            200          0.0.0   \n",
              "1          data-fetch-manager-entry-service            200          1.1.0   \n",
              "2     @hyper.fun/material-icon-dns-outlined            200          1.3.0   \n",
              "3                                xls2enketo            200          0.0.1   \n",
              "4                           stylie.treeview            200          1.0.1   \n",
              "...                                     ...            ...            ...   \n",
              "3328                           openapiproto            200          1.0.0   \n",
              "3329                               taoladat            200          1.0.0   \n",
              "3330                   pouchdb-utils-sapper            200          0.0.3   \n",
              "3331            @react-goosebumps/react-cli            200          0.1.0   \n",
              "3332                     @claudijo/ad-utils            200          0.0.4   \n",
              "\n",
              "      no_of_versions                                           keywords  \\\n",
              "0                1.0                                               None   \n",
              "1                3.0                                               None   \n",
              "2                2.0  [\"hyper-function-component\", \"hfc\", \"icon\", \"m...   \n",
              "3                3.0                                               None   \n",
              "4                2.0  [\"navigation\", \"file browser\", \"menu\", \"css\", ...   \n",
              "...              ...                                                ...   \n",
              "3328             1.0                                               None   \n",
              "3329             1.0                                               None   \n",
              "3330             3.0                                               None   \n",
              "3331             1.0                                               None   \n",
              "3332             4.0                                               None   \n",
              "\n",
              "      no_of_users  has_readme  has_homepage   last_modified_timestamp  \\\n",
              "0             NaN         1.0           0.0  2022-05-07T18:19:55.077Z   \n",
              "1             NaN         1.0           1.0  2023-12-10T15:39:11.400Z   \n",
              "2             NaN         0.0           0.0  2022-08-06T00:34:42.126Z   \n",
              "3             NaN         1.0           0.0  2022-05-25T00:00:44.901Z   \n",
              "4             NaN         1.0           1.0  2022-06-27T01:41:31.505Z   \n",
              "...           ...         ...           ...                       ...   \n",
              "3328          NaN         0.0           0.0  2022-05-12T06:07:38.662Z   \n",
              "3329          NaN         1.0           1.0  2022-05-19T09:32:13.837Z   \n",
              "3330          NaN         1.0           0.0  2022-05-13T07:29:40.911Z   \n",
              "3331          NaN         1.0           0.0  2022-04-06T18:23:50.160Z   \n",
              "3332          NaN         0.0           1.0  2022-04-04T23:14:04.562Z   \n",
              "\n",
              "             created_timestamp  ... gh_net_scrapping_status  \\\n",
              "0     2019-08-08T12:41:10.380Z  ...                    None   \n",
              "1     2023-12-10T13:48:40.949Z  ...                     200   \n",
              "2     2022-07-28T04:31:03.742Z  ...                    None   \n",
              "3     2019-08-30T09:16:27.067Z  ...                    None   \n",
              "4     2015-05-04T22:23:39.685Z  ...                     200   \n",
              "...                        ...  ...                     ...   \n",
              "3328  2020-01-23T22:44:21.347Z  ...                    None   \n",
              "3329  2021-01-06T07:01:11.816Z  ...                    None   \n",
              "3330  2020-04-23T15:19:21.143Z  ...                    None   \n",
              "3331  2018-07-29T20:48:23.968Z  ...                    None   \n",
              "3332  2020-06-29T13:55:14.958Z  ...                     200   \n",
              "\n",
              "     total_lines_of_code  filtered_lines_of_code  no_of_files  \\\n",
              "0                    NaN                     NaN          NaN   \n",
              "1                  463.0                   312.0         15.0   \n",
              "2                    NaN                     NaN          NaN   \n",
              "3                    NaN                     NaN          NaN   \n",
              "4                 6706.0                  1709.0         71.0   \n",
              "...                  ...                     ...          ...   \n",
              "3328                 NaN                     NaN          NaN   \n",
              "3329                 NaN                     NaN          NaN   \n",
              "3330                 NaN                     NaN          NaN   \n",
              "3331                 NaN                     NaN          NaN   \n",
              "3332             20267.0                 17607.0         29.0   \n",
              "\n",
              "      snyk_scrapping_status health_score                  security  \\\n",
              "0                       200           28    SECURITY REVIEW NEEDED   \n",
              "1                       404         None                      None   \n",
              "2                       200            ?                  PENDING…   \n",
              "3                       200           34    SECURITY REVIEW NEEDED   \n",
              "4                       200           42  NO KNOWN SECURITY ISSUES   \n",
              "...                     ...          ...                       ...   \n",
              "3328                    200           40  NO KNOWN SECURITY ISSUES   \n",
              "3329                    200           40  NO KNOWN SECURITY ISSUES   \n",
              "3330                    200           40  NO KNOWN SECURITY ISSUES   \n",
              "3331                    200            ?                  PENDING…   \n",
              "3332                    200           40  NO KNOWN SECURITY ISSUES   \n",
              "\n",
              "      popularity  maintenance community  \n",
              "0        LIMITED     INACTIVE   LIMITED  \n",
              "1           None         None      None  \n",
              "2       PENDING…     PENDING…  PENDING…  \n",
              "3        LIMITED     INACTIVE   LIMITED  \n",
              "4        LIMITED     INACTIVE   LIMITED  \n",
              "...          ...          ...       ...  \n",
              "3328     LIMITED     INACTIVE   LIMITED  \n",
              "3329     LIMITED     INACTIVE   LIMITED  \n",
              "3330     LIMITED     INACTIVE   LIMITED  \n",
              "3331    PENDING…     PENDING…  PENDING…  \n",
              "3332     LIMITED     INACTIVE   LIMITED  \n",
              "\n",
              "[3333 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-157efc4e-f8fb-4b16-9d8c-fe5080764a88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>package</th>\n",
              "      <th>npm_api_status</th>\n",
              "      <th>latest_version</th>\n",
              "      <th>no_of_versions</th>\n",
              "      <th>keywords</th>\n",
              "      <th>no_of_users</th>\n",
              "      <th>has_readme</th>\n",
              "      <th>has_homepage</th>\n",
              "      <th>last_modified_timestamp</th>\n",
              "      <th>created_timestamp</th>\n",
              "      <th>...</th>\n",
              "      <th>gh_net_scrapping_status</th>\n",
              "      <th>total_lines_of_code</th>\n",
              "      <th>filtered_lines_of_code</th>\n",
              "      <th>no_of_files</th>\n",
              "      <th>snyk_scrapping_status</th>\n",
              "      <th>health_score</th>\n",
              "      <th>security</th>\n",
              "      <th>popularity</th>\n",
              "      <th>maintenance</th>\n",
              "      <th>community</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>le-shared-utils-teste-app</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-05-07T18:19:55.077Z</td>\n",
              "      <td>2019-08-08T12:41:10.380Z</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>28</td>\n",
              "      <td>SECURITY REVIEW NEEDED</td>\n",
              "      <td>LIMITED</td>\n",
              "      <td>INACTIVE</td>\n",
              "      <td>LIMITED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data-fetch-manager-entry-service</td>\n",
              "      <td>200</td>\n",
              "      <td>1.1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2023-12-10T15:39:11.400Z</td>\n",
              "      <td>2023-12-10T13:48:40.949Z</td>\n",
              "      <td>...</td>\n",
              "      <td>200</td>\n",
              "      <td>463.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>404</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@hyper.fun/material-icon-dns-outlined</td>\n",
              "      <td>200</td>\n",
              "      <td>1.3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[\"hyper-function-component\", \"hfc\", \"icon\", \"m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-08-06T00:34:42.126Z</td>\n",
              "      <td>2022-07-28T04:31:03.742Z</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>?</td>\n",
              "      <td>PENDING…</td>\n",
              "      <td>PENDING…</td>\n",
              "      <td>PENDING…</td>\n",
              "      <td>PENDING…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xls2enketo</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-05-25T00:00:44.901Z</td>\n",
              "      <td>2019-08-30T09:16:27.067Z</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>34</td>\n",
              "      <td>SECURITY REVIEW NEEDED</td>\n",
              "      <td>LIMITED</td>\n",
              "      <td>INACTIVE</td>\n",
              "      <td>LIMITED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stylie.treeview</td>\n",
              "      <td>200</td>\n",
              "      <td>1.0.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[\"navigation\", \"file browser\", \"menu\", \"css\", ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2022-06-27T01:41:31.505Z</td>\n",
              "      <td>2015-05-04T22:23:39.685Z</td>\n",
              "      <td>...</td>\n",
              "      <td>200</td>\n",
              "      <td>6706.0</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>200</td>\n",
              "      <td>42</td>\n",
              "      <td>NO KNOWN SECURITY ISSUES</td>\n",
              "      <td>LIMITED</td>\n",
              "      <td>INACTIVE</td>\n",
              "      <td>LIMITED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3328</th>\n",
              "      <td>openapiproto</td>\n",
              "      <td>200</td>\n",
              "      <td>1.0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-05-12T06:07:38.662Z</td>\n",
              "      <td>2020-01-23T22:44:21.347Z</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>40</td>\n",
              "      <td>NO KNOWN SECURITY ISSUES</td>\n",
              "      <td>LIMITED</td>\n",
              "      <td>INACTIVE</td>\n",
              "      <td>LIMITED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3329</th>\n",
              "      <td>taoladat</td>\n",
              "      <td>200</td>\n",
              "      <td>1.0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2022-05-19T09:32:13.837Z</td>\n",
              "      <td>2021-01-06T07:01:11.816Z</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>40</td>\n",
              "      <td>NO KNOWN SECURITY ISSUES</td>\n",
              "      <td>LIMITED</td>\n",
              "      <td>INACTIVE</td>\n",
              "      <td>LIMITED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3330</th>\n",
              "      <td>pouchdb-utils-sapper</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-05-13T07:29:40.911Z</td>\n",
              "      <td>2020-04-23T15:19:21.143Z</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>40</td>\n",
              "      <td>NO KNOWN SECURITY ISSUES</td>\n",
              "      <td>LIMITED</td>\n",
              "      <td>INACTIVE</td>\n",
              "      <td>LIMITED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>@react-goosebumps/react-cli</td>\n",
              "      <td>200</td>\n",
              "      <td>0.1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2022-04-06T18:23:50.160Z</td>\n",
              "      <td>2018-07-29T20:48:23.968Z</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200</td>\n",
              "      <td>?</td>\n",
              "      <td>PENDING…</td>\n",
              "      <td>PENDING…</td>\n",
              "      <td>PENDING…</td>\n",
              "      <td>PENDING…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>@claudijo/ad-utils</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0.4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2022-04-04T23:14:04.562Z</td>\n",
              "      <td>2020-06-29T13:55:14.958Z</td>\n",
              "      <td>...</td>\n",
              "      <td>200</td>\n",
              "      <td>20267.0</td>\n",
              "      <td>17607.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>200</td>\n",
              "      <td>40</td>\n",
              "      <td>NO KNOWN SECURITY ISSUES</td>\n",
              "      <td>LIMITED</td>\n",
              "      <td>INACTIVE</td>\n",
              "      <td>LIMITED</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3333 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-157efc4e-f8fb-4b16-9d8c-fe5080764a88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-157efc4e-f8fb-4b16-9d8c-fe5080764a88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-157efc4e-f8fb-4b16-9d8c-fe5080764a88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33c3c06e-ca93-4298-bf9a-4441f5b85aaf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33c3c06e-ca93-4298-bf9a-4441f5b85aaf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33c3c06e-ca93-4298-bf9a-4441f5b85aaf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df = pd.read_sql_query(f\"SELECT * FROM package_data\", conn)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpfKOpb5fAds"
      },
      "source": [
        "# Mining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihJF9Gb46abi",
        "outputId": "89d2b3ef-12de-420a-f355-1fce0879e48c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows mined so far: 3333/3333\n"
          ]
        }
      ],
      "source": [
        "cursor.execute(\"SELECT package FROM package_data\")\n",
        "rows = cursor.fetchall()\n",
        "rows_fetched = len(rows)\n",
        "print(f\"Rows mined so far: {len(rows)}/{len(package_list)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghjXjROqXOUR"
      },
      "outputs": [],
      "source": [
        "cursor.execute(\"SELECT package FROM package_data\")\n",
        "rows = cursor.fetchall()\n",
        "rows_fetched = len(rows)\n",
        "\n",
        "for package in package_list[rows_fetched:]:\n",
        "  print(f\"Now mining\\t{package}\")\n",
        "  final_data = {'package': package}\n",
        "\n",
        "  # mining npm API data\n",
        "  npm_api_url = f\"https://registry.npmjs.org/{package}\"\n",
        "  npm_api_res = fetch_response_without_fail(npm_api_url, {})\n",
        "\n",
        "  npm_api_status, npm_api_res = fetch_response_without_fail(npm_api_url)\n",
        "  final_data['npm_api_status'] = npm_api_status\n",
        "\n",
        "  continue_mining = npm_api_status == \"200\"\n",
        "\n",
        "  if continue_mining:\n",
        "    last_modified_timestamp = GET(npm_api_res, [\"time\", \"modified\"])\n",
        "    final_data['last_modified_timestamp'] = last_modified_timestamp\n",
        "\n",
        "    created_timestamp = GET(npm_api_res, [\"time\", \"created\"])\n",
        "    final_data['created_timestamp'] = created_timestamp\n",
        "\n",
        "    unpublished_timestamp = GET(npm_api_res, [\"time\", \"unpublished\", \"time\"])\n",
        "    final_data['unpublished_timestamp'] = unpublished_timestamp\n",
        "\n",
        "    version_history_timestamps = json.dumps({key: value for key, value in GET(npm_api_res, \"time\").items() if key not in [\"modified\", \"created\", \"unpublished\"]})\n",
        "    final_data['version_history_timestamps'] = version_history_timestamps\n",
        "\n",
        "    no_of_versions = len(json.loads(version_history_timestamps)) if isValid(version_history_timestamps) else None\n",
        "    final_data['no_of_versions'] = no_of_versions\n",
        "\n",
        "    if not isValid(unpublished_timestamp):\n",
        "      latest_version = GET(npm_api_res, [\"dist-tags\", \"latest\"])\n",
        "      final_data['latest_version'] = latest_version\n",
        "\n",
        "      versions = GET(npm_api_res, \"versions\")\n",
        "\n",
        "      keywords = GET(versions, [latest_version, 'keywords'])\n",
        "      final_data['keywords'] = json.dumps(keywords) if isValid(keywords) else None\n",
        "\n",
        "      no_of_users = getN(GET(npm_api_res, 'users'))\n",
        "      final_data['no_of_users'] = no_of_users\n",
        "\n",
        "      has_readme = isValid(GET(npm_api_res, \"readmeFilename\"))\n",
        "      final_data['has_readme'] = has_readme\n",
        "\n",
        "      has_homepage = isValid(GET(npm_api_res, \"homepage\"))\n",
        "      final_data['has_homepage'] = has_homepage\n",
        "\n",
        "      is_deprecated = isValid(GET(versions, [latest_version, 'deprecated']))\n",
        "      final_data['is_deprecated'] = is_deprecated\n",
        "\n",
        "      unpack_size = GET(versions, [latest_version, 'dist', 'unpackedSize'])\n",
        "      final_data['unpack_size'] = unpack_size\n",
        "\n",
        "      file_count = GET(versions, [latest_version, 'dist', 'fileCount'])\n",
        "      final_data['file_count'] = file_count\n",
        "\n",
        "      dependencies = GET(versions, [latest_version, 'dependencies'], {})\n",
        "      dev_dependencies = GET(versions, [latest_version, 'devDependencies'], {})\n",
        "      no_of_dependencies = len(dependencies) + len(dev_dependencies)\n",
        "      final_data['no_of_dependencies'] = no_of_dependencies\n",
        "\n",
        "      stat, lagging_dependencies_count = get_lagging_dependencies_count(dependencies)\n",
        "      stat_dev, lagging_dev_dependencies_count = get_lagging_dependencies_count(dev_dependencies)\n",
        "      if stat == 'success' and stat_dev == 'success':\n",
        "        final_data['lagging_dependencies_count_status'] = 'success'\n",
        "        final_data['lagging_dependencies_count'] = lagging_dependencies_count + lagging_dev_dependencies_count\n",
        "      else:\n",
        "        final_data['lagging_dependencies_count_status'] = 'erred'\n",
        "\n",
        "      has_repository = isValid(GET(npm_api_res, [\"repository\"]))\n",
        "      final_data['has_repository'] = has_repository\n",
        "\n",
        "      repository_type = GET(npm_api_res, [\"repository\", \"type\"])\n",
        "      final_data['repository_type'] = repository_type\n",
        "\n",
        "      repository_url = GET(npm_api_res, [\"repository\", \"url\"])\n",
        "      final_data['repository_url'] = repository_url\n",
        "\n",
        "      git_repository_url = extract_github_url(repository_url)\n",
        "      final_data['git_repository_url'] = git_repository_url\n",
        "\n",
        "  print(\"NPM API mined\")\n",
        "  continue_mining = continue_mining and not isValid(unpublished_timestamp)\n",
        "  if continue_mining:\n",
        "    # mining libraries.io API data\n",
        "    li_api_url = f\"https://libraries.io/api/npm/{package}\"\n",
        "    li_api_status, li_api_res = fetch_response_without_fail(li_api_url, {'api_key': li_api_key})\n",
        "    final_data['li_api_status'] = li_api_status\n",
        "\n",
        "    if li_api_status == '200':\n",
        "      rank = GET(li_api_res, \"rank\")\n",
        "      final_data['rank'] = rank\n",
        "\n",
        "      dependants_count = GET(li_api_res, \"dependents_count\")\n",
        "      final_data['dependants_count'] = dependants_count\n",
        "\n",
        "      dependant_repos_count = GET(li_api_res, \"dependent_repos_count\")\n",
        "      final_data['dependant_repos_count'] = dependant_repos_count\n",
        "\n",
        "    print(\"Libraries.io API mined\")\n",
        "    # scrapping snyk.io data\n",
        "    snyk_scrapping_status, snyk_scrapping_res = scrap_snyk(package)\n",
        "    final_data['snyk_scrapping_status'] = snyk_scrapping_status\n",
        "\n",
        "    if snyk_scrapping_status == '200':\n",
        "      final_data['health_score'] = snyk_scrapping_res['health_score']\n",
        "      final_data['security'] = snyk_scrapping_res['security']\n",
        "      final_data['popularity'] = snyk_scrapping_res['popularity']\n",
        "      final_data['maintenance'] = snyk_scrapping_res['maintenance']\n",
        "      final_data['community'] = snyk_scrapping_res['community']\n",
        "\n",
        "    print(\"snyk.io API mined\")\n",
        "    # mining github API data\n",
        "    # getting redirected gh url\n",
        "    if isValid(git_repository_url):\n",
        "      try:\n",
        "        git_repository_url_final = requests.get(git_repository_url, allow_redirects=False).headers['Location']\n",
        "      except Exception as e:\n",
        "        git_repository_url_final = git_repository_url\n",
        "\n",
        "      # checking if url is valid\n",
        "      try:\n",
        "        res = requests.get(git_repository_url_final)\n",
        "        git_repository_status = str(res.status_code)\n",
        "      except Exception as e:\n",
        "        git_repository_status = f'Exception: {e}'\n",
        "      final_data['git_repository_status'] = git_repository_status\n",
        "      continue_mining = continue_mining and git_repository_status == '200'\n",
        "    else:\n",
        "      continue_mining = False\n",
        "\n",
        "  # continue github mining\n",
        "  if continue_mining:\n",
        "    print(\"Git URL OK,  Continuing...\")\n",
        "    final_data['git_repository_url_final'] = git_repository_url_final\n",
        "\n",
        "    headers = {\n",
        "      'Authorization': f'token {gh_token}',\n",
        "      'Accept': 'application/vnd.github.v3+json'\n",
        "    }\n",
        "\n",
        "    repo_owner, repo_name = git_repository_url_final.split('/')[-2:]\n",
        "    gh_api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}\"\n",
        "\n",
        "    # mining github API data\n",
        "    gh_api_status, gh_api_res = fetch_response_without_fail(gh_api_url, headers=headers)\n",
        "    final_data['gh_api_status'] = gh_api_status\n",
        "    if gh_api_status == '200':\n",
        "      forks = GET(gh_api_res, 'forks_count')\n",
        "      final_data['forks'] = forks\n",
        "\n",
        "      stars = GET(gh_api_res, 'stargazers_count')\n",
        "      final_data['stars'] = stars\n",
        "\n",
        "      watchers = GET(gh_api_res, 'subscribers_count')\n",
        "      final_data['watchers'] = watchers\n",
        "\n",
        "      start_date_timestamp = GET(gh_api_res, 'created_at')\n",
        "      if isValid(start_date_timestamp):\n",
        "        start_date = datetime.strptime(start_date_timestamp, \"%Y-%m-%dT%H:%M:%SZ\").date()\n",
        "        # age till Feb 23, 2024\n",
        "        end_date = datetime(2024, 2, 23).date()\n",
        "        total_days = (end_date - start_date).days\n",
        "      else:\n",
        "        total_days = None\n",
        "\n",
        "\n",
        "    # mining github issues API data\n",
        "    gh_issues_api_url = f\"https://api.github.com/search/issues?q=is:issue%20is:open%20repo:{repo_owner}/{repo_name}\"\n",
        "    gh_issue_api_status, gh_issues_api_res = fetch_response_without_fail(gh_issues_api_url, headers={'Authorization': f'token {gh_token}'})\n",
        "    final_data['gh_issue_api_status'] = gh_issue_api_status\n",
        "    if gh_issue_api_status == '200':\n",
        "      issues = GET(gh_issues_api_res, 'total_count')\n",
        "      final_data['issues'] = issues\n",
        "\n",
        "\n",
        "    # mining github pr API data\n",
        "    gh_pr_api_url = f\"https://api.github.com/search/issues?q=is:pr%20is:open%20repo:{repo_owner}/{repo_name}\"\n",
        "    gh_pr_api_status, gh_pr_api_res = fetch_response_without_fail(gh_pr_api_url, headers={'Authorization': f'token {gh_token}'})\n",
        "    final_data['gh_pr_api_status'] = gh_pr_api_status\n",
        "    if gh_pr_api_status == '200':\n",
        "      pr = GET(gh_pr_api_res, 'total_count')\n",
        "      final_data['pr'] = pr\n",
        "\n",
        "\n",
        "    # scrapping repository data\n",
        "    gh_scrapping_status, gh_scrapping_res = scrap_repo(git_repository_url_final)\n",
        "    final_data['gh_scrapping_status'] = gh_scrapping_status\n",
        "\n",
        "    if gh_scrapping_status == '200':\n",
        "      final_data['contributors'] = gh_scrapping_res['contributors']\n",
        "      final_data['no_of_commits'] = gh_scrapping_res['no_of_commits']\n",
        "      final_data['avg_commit_freq'] = gh_scrapping_res['no_of_commits'] / total_days if isValid(total_days) else None\n",
        "\n",
        "\n",
        "    # scrapping repository network data\n",
        "    gh_net_scrapping_status, gh_net_scrapping_res = scrap_repo_net(git_repository_url_final)\n",
        "    final_data['gh_net_scrapping_status'] = gh_net_scrapping_status\n",
        "\n",
        "    if gh_net_scrapping_status == '200':\n",
        "      final_data['dependants_count'] = gh_net_scrapping_res['dependants_count']\n",
        "      final_data['dependant_repos_count'] = gh_net_scrapping_res['dependant_repos_count']\n",
        "\n",
        "    # pydriller\n",
        "    try:\n",
        "      old_data = fetch_package_data_from_db('FINAL_PACKAGE_DATA.db', package, 'final_package_data')\n",
        "      if isValid(old_data) and (isValid(old_data['Lines Of Codes']) or isValid(old_data['Number of Files']) or isValid(old_data['Filtered Lines of Codes'])):\n",
        "        final_data['total_lines_of_code'] = old_data['Lines Of Codes']\n",
        "        final_data['filtered_lines_of_code'] = old_data['Number of Files']\n",
        "        final_data['no_of_files'] = old_data['Filtered Lines of Codes']\n",
        "      else:\n",
        "        # some repo urls have been same for multiple packages so fetching data from them instead of recalculating\n",
        "        cursor.execute(\"SELECT total_lines_of_code, filtered_lines_of_code, no_of_files FROM package_data WHERE git_repository_url_final = ? AND (total_lines_of_code IS NOT NULL OR filtered_lines_of_code IS NOT NULL OR no_of_files IS NOT NULL)\", [git_repository_url_final])\n",
        "        result_to_check = cursor.fetchone()\n",
        "        if isValid(result_to_check):\n",
        "          final_data['total_lines_of_code'], final_data['filtered_lines_of_code'], final_data['no_of_files'] = result_to_check\n",
        "        else:\n",
        "          # If the result is empty or values are None, calculate the lines of code\n",
        "          total_lines_of_code, filtered_lines_of_code, no_of_files = count_lines_of_code(git_repository_url_final)\n",
        "          final_data['total_lines_of_code'] = total_lines_of_code\n",
        "          final_data['filtered_lines_of_code'] = filtered_lines_of_code\n",
        "          final_data['no_of_files'] = no_of_files\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"pydriller failed for {package}\\n{e}\")\n",
        "  else:\n",
        "    print(\"Git URL Not OK,  Skipping...\")\n",
        "\n",
        "  if len(final_data) > 0:\n",
        "    columns = ', '.join(final_data.keys())\n",
        "    values = ', '.join(['?' for _ in final_data.values()])\n",
        "\n",
        "    # Execute the INSERT statement\n",
        "    cursor.execute(f\"INSERT INTO package_data ({columns}) VALUES ({values})\", tuple(final_data.values()))\n",
        "\n",
        "    # Commit the changes and close the database connection\n",
        "    conn.commit()\n",
        "\n",
        "  rows_fetched += 1\n",
        "  print(\"--------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  print(f\"Rows fetched so far: {rows_fetched}/{len(package_list)}\")\n",
        "  print(\"--------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCK1YoIQBqRQ"
      },
      "outputs": [],
      "source": [
        "conn.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5TkJKg7MJOpQ",
        "7kyxTPar_4kd",
        "PQkSHf9cLU_E",
        "gdSaTfR7Gkn0",
        "jpfKOpb5fAds"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}